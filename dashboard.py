"""
Streamlit Dashboard for Predictive Maintenance
Delta Industries Ltd.

Interactive dashboard for project evaluation featuring:
- RUL predictions (primary focus)
- Failure flags and risk categories (primary focus)
- Machine health overview
- Actionable maintenance recommendations
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import warnings
import joblib
from sklearn.metrics import (
    mean_absolute_error,
    mean_squared_error,
    r2_score,
    roc_auc_score,
    precision_score,
    recall_score,
    confusion_matrix,
)
import subprocess
import os
from io import BytesIO
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas

warnings.filterwarnings('ignore')

# Page configuration
st.set_page_config(
    page_title="Delta Industries - Predictive Maintenance",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for a modern, minimal layout
st.markdown("""
    <style>
    .main-header {
        font-size: 2.1rem;
        font-weight: 600;
        color: #111827;
        text-align: left;
        margin-bottom: 0.5rem;
    }
    .subheader-text {
        color: #4b5563;
        font-size: 0.95rem;
        margin-bottom: 1.5rem;
    }
    .section-card {
        background-color: #ffffff;
        padding: 1.2rem 1.4rem;
        border-radius: 0.6rem;
        border: 1px solid #e5e7eb;
        box-shadow: 0 1px 2px rgba(15, 23, 42, 0.03);
        margin-bottom: 1.2rem;
    }
    .muted-text {
        color: #6b7280;
        font-size: 0.9rem;
    }
    </style>
""", unsafe_allow_html=True)

@st.cache_data
def load_dashboard_data():
    """Load dashboard outputs CSV."""
    try:
        df = pd.read_csv('outputs/dashboard_outputs.csv')
        df['snapshot_date'] = pd.to_datetime(df['snapshot_date'])
        return df
    except FileNotFoundError:
        st.error("❌ Dashboard outputs file not found. Please run 'python3 generate_dashboard_outputs.py' first.")
        st.stop()


@st.cache_data
def load_raw_dataset():
    """Load the base machine health dataset generated by data_generation.py."""
    try:
        df = pd.read_csv('outputs/delta_industries_machine_health.csv')
        df['snapshot_date'] = pd.to_datetime(df['snapshot_date'])
        return df
    except FileNotFoundError:
        return None


@st.cache_resource
def load_models():
    """Load trained models and scalers for on-dashboard evaluation."""
    try:
        rul_model = joblib.load('outputs/rul_model.pkl')
        rul_scaler = joblib.load('outputs/rul_scaler.pkl')
        failure_model = joblib.load('outputs/failure_risk_model.pkl')
        failure_scaler = joblib.load('outputs/failure_risk_scaler.pkl')
        return rul_model, rul_scaler, failure_model, failure_scaler
    except FileNotFoundError:
        return None, None, None, None


@st.cache_data
def compute_model_metrics():
    """
    Compute key regression and classification metrics plus confusion matrix
    using the full dataset and saved models.
    """
    base_df = load_raw_dataset()
    rul_model, rul_scaler, failure_model, failure_scaler = load_models()

    if base_df is None or rul_model is None or failure_model is None:
        return None

    # Prepare features (same logic as modeling.py / generate_dashboard_outputs.py)
    df_encoded = pd.get_dummies(base_df, columns=['machine_type'], prefix='type', drop_first=True)
    exclude_cols = ['machine_id', 'snapshot_date', 'RUL_days', 'fail_in_30d']
    feature_cols = [col for col in df_encoded.columns if col not in exclude_cols]
    X = df_encoded[feature_cols]

    # True targets
    y_rul = base_df['RUL_days'].values
    y_failure = base_df['fail_in_30d'].values

    # RUL metrics
    X_rul_scaled = rul_scaler.transform(X)
    rul_pred = rul_model.predict(X_rul_scaled)
    rul_mae = mean_absolute_error(y_rul, rul_pred)
    rul_rmse = mean_squared_error(y_rul, rul_pred, squared=False)
    rul_r2 = r2_score(y_rul, rul_pred)

    # Failure classification metrics
    X_fail_scaled = failure_scaler.transform(X)
    failure_proba = failure_model.predict_proba(X_fail_scaled)[:, 1]
    failure_pred = failure_model.predict(X_fail_scaled)

    auc = roc_auc_score(y_failure, failure_proba)
    precision = precision_score(y_failure, failure_pred)
    recall = recall_score(y_failure, failure_pred)
    cm = confusion_matrix(y_failure, failure_pred)

    metrics = {
        "rul": {
            "mae": rul_mae,
            "rmse": rul_rmse,
            "r2": rul_r2,
        },
        "failure": {
            "auc": auc,
            "precision": precision,
            "recall": recall,
            "confusion_matrix": cm,
        },
    }
    return metrics


def get_color_for_risk(risk_category):
    """Return color code for risk category."""
    colors = {
        'RED': '#d32f2f',
        'YELLOW': '#f57c00',
        'GREEN': '#388e3c'
    }
    return colors.get(risk_category, '#757575')


def run_full_pipeline():
    """
    Regenerate data, retrain models, and recreate dashboard outputs by
    calling run_all.py. This keeps the dashboard in sync with new data.
    """
    with st.spinner("Running full pipeline (data generation, EDA, modeling, evaluation, dashboard outputs)..."):
        try:
            # Ensure we run from project root
            project_root = os.path.dirname(os.path.abspath(__file__))
            result = subprocess.run(
                ["python3", "run_all.py"],
                cwd=project_root,
                capture_output=True,
                text=True,
                check=True,
            )
            st.success("Full pipeline completed successfully. Dashboard data refreshed.")
            with st.expander("Show pipeline logs"):
                st.text(result.stdout)
                if result.stderr:
                    st.text("\n[stderr]\n" + result.stderr)
        except subprocess.CalledProcessError as e:
            st.error("Pipeline execution failed. Please check the logs below.")
            with st.expander("Show error details"):
                st.text(e.stdout or "")
                st.text("\n[stderr]\n" + (e.stderr or ""))


def build_pdf_report(base_df, model_metrics):
    """Build a concise PDF report summarizing dataset, models, and assumptions."""
    buffer = BytesIO()
    c = canvas.Canvas(buffer, pagesize=A4)
    width, height = A4
    y = height - 50

    c.setFont("Helvetica-Bold", 16)
    c.drawString(50, y, "Delta Industries - Predictive Maintenance Report")
    y -= 30

    c.setFont("Helvetica", 10)
    c.drawString(50, y, f"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    y -= 25

    # Dataset section
    c.setFont("Helvetica-Bold", 12)
    c.drawString(50, y, "1. Dataset Overview")
    y -= 18
    c.setFont("Helvetica", 10)
    total_rows = len(base_df)
    machines = base_df["machine_id"].nunique()
    date_min = base_df["snapshot_date"].min().strftime("%Y-%m-%d")
    date_max = base_df["snapshot_date"].max().strftime("%Y-%m-%d")
    c.drawString(60, y, f"- Total records: {total_rows}")
    y -= 14
    c.drawString(60, y, f"- Unique machines: {machines}")
    y -= 14
    c.drawString(60, y, f"- Snapshot date range: {date_min} to {date_max}")
    y -= 20

    # Model metrics section
    c.setFont("Helvetica-Bold", 12)
    c.drawString(50, y, "2. Model Performance")
    y -= 18
    c.setFont("Helvetica-Bold", 11)
    c.drawString(60, y, "RUL Model (Linear Regression)")
    y -= 14
    c.setFont("Helvetica", 10)
    c.drawString(70, y, f"- MAE: {model_metrics['rul']['mae']:.1f} days")
    y -= 14
    c.drawString(70, y, f"- RMSE: {model_metrics['rul']['rmse']:.1f} days")
    y -= 14
    c.drawString(70, y, f"- R-squared: {model_metrics['rul']['r2']:.3f}")
    y -= 18

    c.setFont("Helvetica-Bold", 11)
    c.drawString(60, y, "Failure Risk Model (Logistic Regression)")
    y -= 14
    c.setFont("Helvetica", 10)
    c.drawString(70, y, f"- ROC-AUC: {model_metrics['failure']['auc']:.3f}")
    y -= 14
    c.drawString(70, y, f"- Precision: {model_metrics['failure']['precision']:.3f}")
    y -= 14
    c.drawString(70, y, f"- Recall: {model_metrics['failure']['recall']:.3f}")
    y -= 20

    # Cost assumptions section (aligned with evaluation.py)
    c.setFont("Helvetica-Bold", 12)
    c.drawString(50, y, "3. Cost Assumptions")
    y -= 18
    c.setFont("Helvetica", 10)
    c.drawString(60, y, "- Planned maintenance cost: $2,000 per machine")
    y -= 14
    c.drawString(60, y, "- Unplanned downtime cost: $10,000 per machine")
    y -= 14
    c.drawString(60, y, "- Emergency repair cost: $5,000 per machine")
    y -= 20

    c.setFont("Helvetica-Bold", 12)
    c.drawString(50, y, "4. Risk Categories and Business Rules")
    y -= 18
    c.setFont("Helvetica", 10)
    c.drawString(60, y, "- RED: failure_probability ≥ 0.7 or RUL ≤ 30 days")
    y -= 14
    c.drawString(60, y, "- YELLOW: failure_probability ≥ 0.4 or RUL ≤ 60 days")
    y -= 14
    c.drawString(60, y, "- GREEN: otherwise (monitor only)")

    c.showPage()
    c.save()
    buffer.seek(0)
    return buffer


def main():
    # Header and introduction
    st.markdown('<div class="main-header">Delta Industries - Predictive Maintenance Dashboard</div>', unsafe_allow_html=True)
    st.markdown('<div class="subheader-text">Remaining useful life and failure risk insights for production machinery, with clear business assumptions and cost-aware recommendations.</div>', unsafe_allow_html=True)
    
    # Load data
    df = load_dashboard_data()
    base_df = load_raw_dataset()
    model_metrics = compute_model_metrics()
    
    # Sidebar controls: data actions + filters
    st.sidebar.header("Data and pipeline")
    col_generate, col_download = st.sidebar.columns(2)
    with col_generate:
        if st.button("Run pipeline", help="Regenerate data, retrain models, and refresh dashboard outputs."):
            run_full_pipeline()
            # Clear caches so fresh data is used on next rerun
            load_dashboard_data.clear()
            load_raw_dataset.clear()
            compute_model_metrics.clear()
            st.experimental_rerun()
    with col_download:
        if base_df is not None:
            st.download_button(
                label="Download CSV",
                data=base_df.to_csv(index=False),
                file_name="delta_industries_machine_health.csv",
                mime="text/csv",
                help="Download the underlying machine health dataset.",
            )
        else:
            st.caption("Base dataset not found yet. Run the pipeline first.")
    
    # Sidebar filters
    st.sidebar.header("Filters")
    
    # Machine type filter
    machine_types = ['All'] + sorted(df['machine_type'].unique().tolist())
    selected_machine_type = st.sidebar.selectbox("Machine Type", machine_types)
    
    # Risk category filter
    risk_categories = ['All'] + sorted(df['risk_category'].unique().tolist())
    selected_risk = st.sidebar.selectbox("Risk Category", risk_categories)
    
    # Criticality filter
    criticality_scores = ['All'] + sorted(df['criticality_score'].unique().tolist())
    selected_criticality = st.sidebar.selectbox("Criticality Score", criticality_scores)
    
    # Failure flag filter
    failure_flag_filter = st.sidebar.selectbox("Failure Flag", ['All', 'Flagged (1)', 'Not Flagged (0)'])
    
    # Apply filters
    filtered_df = df.copy()
    if selected_machine_type != 'All':
        filtered_df = filtered_df[filtered_df['machine_type'] == selected_machine_type]
    if selected_risk != 'All':
        filtered_df = filtered_df[filtered_df['risk_category'] == selected_risk]
    if selected_criticality != 'All':
        filtered_df = filtered_df[filtered_df['criticality_score'] == selected_criticality]
    if failure_flag_filter == 'Flagged (1)':
        filtered_df = filtered_df[filtered_df['failure_flag'] == 1]
    elif failure_flag_filter == 'Not Flagged (0)':
        filtered_df = filtered_df[filtered_df['failure_flag'] == 0]
    
    # Key Metrics Row
    st.subheader("Key metrics")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Machines", len(filtered_df))
    
    with col2:
        red_count = len(filtered_df[filtered_df['risk_category'] == 'RED'])
        st.metric("At risk (RED)", red_count, delta=f"{red_count - len(df[df['risk_category'] == 'RED'])}")
    
    with col3:
        avg_rul = filtered_df['RUL_days_predicted'].mean()
        st.metric("Average RUL", f"{avg_rul:.1f} days")
    
    with col4:
        avg_failure_prob = filtered_df['failure_probability'].mean()
        st.metric("Avg Failure Probability", f"{avg_failure_prob:.1%}")
    
    st.markdown("---")
    
    # Explanatory overview cards
    st.markdown(" ")
    info_col1, info_col2, info_col3 = st.columns(3)
    with info_col1:
        with st.container():
            st.markdown('<div class="section-card"><strong>Dataset</strong><br><span class="muted-text">Synthetic machine-health data for Delta Industries, with weekly snapshots per machine, sensor readings, degradation patterns, and engineered targets for remaining useful life (RUL) and 30-day failure risk.</span></div>', unsafe_allow_html=True)
    with info_col2:
        with st.container():
            st.markdown('<div class="section-card"><strong>Models</strong><br><span class="muted-text">A linear regression model predicts continuous RUL in days, and a logistic regression model estimates the probability of failure within 30 days, using scaled numerical features and encoded machine types.</span></div>', unsafe_allow_html=True)
    with info_col3:
        with st.container():
            st.markdown('<div class="section-card"><strong>Cost and risk logic</strong><br><span class="muted-text">Business rules classify machines into RED, YELLOW, and GREEN categories using RUL and failure probability, assuming $2k planned maintenance, $10k downtime, and $5k emergency repair per failure.</span></div>', unsafe_allow_html=True)

    st.markdown("---")

    # Main Dashboard Sections
    # Row 1: RUL Overview and Failure Risk Distribution
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("RUL overview")
        
        # RUL Distribution Histogram
        fig_rul_hist = px.histogram(
            filtered_df,
            x='RUL_days_predicted',
            nbins=30,
            title='RUL Distribution',
            labels={'RUL_days_predicted': 'Remaining Useful Life (Days)', 'count': 'Number of Machines'},
            color_discrete_sequence=['#1f77b4']
        )
        fig_rul_hist.add_vline(x=30, line_dash="dash", line_color="red", annotation_text="30 days threshold")
        fig_rul_hist.add_vline(x=60, line_dash="dash", line_color="orange", annotation_text="60 days threshold")
        fig_rul_hist.update_layout(height=400)
        st.plotly_chart(fig_rul_hist, use_container_width=True)
        
        # RUL vs Actual RUL Comparison (if available)
        if 'actual_RUL_days' in filtered_df.columns:
            fig_rul_comparison = px.scatter(
                filtered_df,
                x='actual_RUL_days',
                y='RUL_days_predicted',
                color='risk_category',
                color_discrete_map={'RED': '#d32f2f', 'YELLOW': '#f57c00', 'GREEN': '#388e3c'},
                title='Predicted vs Actual RUL',
                labels={'actual_RUL_days': 'Actual RUL (Days)', 'RUL_days_predicted': 'Predicted RUL (Days)'},
                hover_data=['machine_id', 'failure_probability']
            )
            # Add diagonal line
            max_val = max(filtered_df['actual_RUL_days'].max(), filtered_df['RUL_days_predicted'].max())
            fig_rul_comparison.add_trace(go.Scatter(
                x=[0, max_val],
                y=[0, max_val],
                mode='lines',
                line=dict(dash='dash', color='gray'),
                name='Perfect Prediction'
            ))
            fig_rul_comparison.update_layout(height=400)
            st.plotly_chart(fig_rul_comparison, use_container_width=True)
    
    with col2:
        st.subheader("Failure risk distribution")
        
        # Risk Category Pie Chart
        risk_counts = filtered_df['risk_category'].value_counts()
        fig_pie = px.pie(
            values=risk_counts.values,
            names=risk_counts.index,
            title='Risk Category Distribution',
            color=risk_counts.index,
            color_discrete_map={'RED': '#d32f2f', 'YELLOW': '#f57c00', 'GREEN': '#388e3c'}
        )
        fig_pie.update_layout(height=400)
        st.plotly_chart(fig_pie, use_container_width=True)
        
        # Failure Probability Distribution
        fig_failure_prob = px.histogram(
            filtered_df,
            x='failure_probability',
            nbins=30,
            title='Failure Probability Distribution',
            labels={'failure_probability': 'Failure Probability', 'count': 'Number of Machines'},
            color='risk_category',
            color_discrete_map={'RED': '#d32f2f', 'YELLOW': '#f57c00', 'GREEN': '#388e3c'}
        )
        fig_failure_prob.add_vline(x=0.7, line_dash="dash", line_color="red", annotation_text="70% threshold")
        fig_failure_prob.add_vline(x=0.4, line_dash="dash", line_color="orange", annotation_text="40% threshold")
        fig_failure_prob.update_layout(height=400)
        st.plotly_chart(fig_failure_prob, use_container_width=True)
    
    st.markdown("---")
    
    # Model Performance Summary
    if model_metrics is not None:
        st.subheader("Model performance (full dataset)")
        col_rul, col_fail = st.columns(2)

        with col_rul:
            st.markdown("**RUL Model (Linear Regression)**")
            st.metric("MAE", f"{model_metrics['rul']['mae']:.1f} days")
            st.metric("RMSE", f"{model_metrics['rul']['rmse']:.1f} days")
            st.metric("R²", f"{model_metrics['rul']['r2']:.3f}")

        with col_fail:
            st.markdown("**Failure Risk Model (Logistic Regression)**")
            st.metric("ROC-AUC", f"{model_metrics['failure']['auc']:.3f}")
            st.metric("Precision", f"{model_metrics['failure']['precision']:.3f}")
            st.metric("Recall", f"{model_metrics['failure']['recall']:.3f}")

        # Confusion matrix heatmap
        cm = model_metrics["failure"]["confusion_matrix"]
        cm_fig = px.imshow(
            cm,
            text_auto=True,
            color_continuous_scale="Blues",
            labels=dict(x="Predicted", y="Actual", color="Count"),
            x=["Low Risk (0)", "High Risk (1)"],
            y=["Low Risk (0)", "High Risk (1)"],
        )
        cm_fig.update_layout(
            title="Failure Risk Model - Confusion Matrix",
            height=400,
        )
        st.plotly_chart(cm_fig, use_container_width=True)
    else:
        st.info("Model performance metrics are not available yet. Run the full pipeline to train models and generate data.")
    
    st.markdown("---")
    
    # Alert Panel - RED Category Machines
    st.subheader("Urgent action required (RED category)")
    red_machines = filtered_df[filtered_df['risk_category'] == 'RED'].copy()
    
    if len(red_machines) > 0:
        # Sort by RUL (lowest first) and failure probability (highest first)
        red_machines = red_machines.sort_values(['RUL_days_predicted', 'failure_probability'], ascending=[True, False])
        
        # Display key metrics for RED machines
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Total RED Machines", len(red_machines))
        with col2:
            st.metric("Lowest RUL", f"{red_machines['RUL_days_predicted'].min():.1f} days")
        with col3:
            st.metric("Highest Failure Prob", f"{red_machines['failure_probability'].max():.1%}")
        
        # Display table
        display_cols = ['machine_id', 'machine_type', 'RUL_days_predicted', 'failure_probability', 
                       'criticality_score', 'snapshot_date']
        red_display = red_machines[display_cols].copy()
        red_display['RUL_days_predicted'] = red_display['RUL_days_predicted'].round(1)
        red_display['failure_probability'] = red_display['failure_probability'].apply(lambda x: f"{x:.1%}")
        red_display['snapshot_date'] = red_display['snapshot_date'].dt.strftime('%Y-%m-%d')
        red_display.columns = ['Machine ID', 'Machine Type', 'RUL (Days)', 'Failure Probability', 
                              'Criticality', 'Snapshot Date']
        
        st.dataframe(red_display, use_container_width=True, hide_index=True)
        
        # Action recommendations
        st.info("Action required: schedule maintenance within 1 week for these machines. Prepare spare parts and assign priority technicians.")
    else:
        st.success("✅ No machines currently in RED category. All systems operating normally.")
    
    st.markdown("---")
    
    # Machine Details Table
    st.subheader("Machine details")
    
    # Sort options
    sort_by = st.selectbox("Sort by", ['RUL (Lowest First)', 'RUL (Highest First)', 
                                       'Failure Probability (Highest First)', 'Failure Probability (Lowest First)',
                                       'Machine ID', 'Risk Category'])
    
    display_df = filtered_df.copy()
    
    if sort_by == 'RUL (Lowest First)':
        display_df = display_df.sort_values('RUL_days_predicted', ascending=True)
    elif sort_by == 'RUL (Highest First)':
        display_df = display_df.sort_values('RUL_days_predicted', ascending=False)
    elif sort_by == 'Failure Probability (Highest First)':
        display_df = display_df.sort_values('failure_probability', ascending=False)
    elif sort_by == 'Failure Probability (Lowest First)':
        display_df = display_df.sort_values('failure_probability', ascending=True)
    elif sort_by == 'Machine ID':
        display_df = display_df.sort_values('machine_id', ascending=True)
    elif sort_by == 'Risk Category':
        risk_order = {'RED': 1, 'YELLOW': 2, 'GREEN': 3}
        display_df['risk_order'] = display_df['risk_category'].map(risk_order)
        display_df = display_df.sort_values('risk_order', ascending=True)
        display_df = display_df.drop('risk_order', axis=1)
    
    # Prepare display columns
    table_cols = ['machine_id', 'machine_type', 'RUL_days_predicted', 'failure_probability',
                  'risk_category', 'failure_flag', 'criticality_score', 'snapshot_date']
    if 'actual_RUL_days' in display_df.columns:
        table_cols.insert(4, 'actual_RUL_days')
    
    table_df = display_df[table_cols].copy()
    table_df['RUL_days_predicted'] = table_df['RUL_days_predicted'].round(1)
    table_df['failure_probability'] = table_df['failure_probability'].apply(lambda x: f"{x:.1%}")
    if 'actual_RUL_days' in table_df.columns:
        table_df['actual_RUL_days'] = table_df['actual_RUL_days'].round(1)
    table_df['snapshot_date'] = table_df['snapshot_date'].dt.strftime('%Y-%m-%d')
    
    # Rename columns for display
    column_mapping = {
        'machine_id': 'Machine ID',
        'machine_type': 'Machine Type',
        'RUL_days_predicted': 'RUL (Days)',
        'failure_probability': 'Failure Probability',
        'risk_category': 'Risk Category',
        'failure_flag': 'Failure Flag',
        'criticality_score': 'Criticality',
        'snapshot_date': 'Snapshot Date'
    }
    if 'actual_RUL_days' in table_df.columns:
        column_mapping['actual_RUL_days'] = 'Actual RUL (Days)'
    
    table_df = table_df.rename(columns=column_mapping)
    
    # Color code the dataframe
    def color_risk_category(val):
        if val == 'RED':
            return 'background-color: #ffebee'
        elif val == 'YELLOW':
            return 'background-color: #fff3e0'
        elif val == 'GREEN':
            return 'background-color: #e8f5e9'
        return ''
    
    styled_df = table_df.style.applymap(color_risk_category, subset=['Risk Category'])
    st.dataframe(styled_df, use_container_width=True, hide_index=True)
    
    st.markdown("---")
    
    # Maintenance Schedule
    st.subheader("Maintenance schedule")
    
    # Create maintenance schedule based on RUL
    schedule_df = filtered_df.copy()
    schedule_df['recommended_maintenance_date'] = pd.to_datetime(schedule_df['snapshot_date']) + pd.to_timedelta(schedule_df['RUL_days_predicted'], unit='D')
    schedule_df['days_until_maintenance'] = (schedule_df['recommended_maintenance_date'] - pd.to_datetime('today')).dt.days
    
    # Sort by priority (RED first, then by RUL)
    risk_order = {'RED': 1, 'YELLOW': 2, 'GREEN': 3}
    schedule_df['risk_order'] = schedule_df['risk_category'].map(risk_order)
    schedule_df = schedule_df.sort_values(['risk_order', 'RUL_days_predicted'], ascending=[True, True])
    schedule_df = schedule_df.drop('risk_order', axis=1)
    
    # Display schedule
    schedule_cols = ['machine_id', 'machine_type', 'RUL_days_predicted', 'failure_probability',
                    'risk_category', 'recommended_maintenance_date', 'days_until_maintenance']
    schedule_display = schedule_df[schedule_cols].copy()
    schedule_display['RUL_days_predicted'] = schedule_display['RUL_days_predicted'].round(1)
    schedule_display['failure_probability'] = schedule_display['failure_probability'].apply(lambda x: f"{x:.1%}")
    schedule_display['recommended_maintenance_date'] = schedule_display['recommended_maintenance_date'].dt.strftime('%Y-%m-%d')
    schedule_display.columns = ['Machine ID', 'Machine Type', 'RUL (Days)', 'Failure Probability',
                                'Risk Category', 'Recommended Date', 'Days Until']
    
    st.dataframe(schedule_display.head(50), use_container_width=True, hide_index=True)
    
    st.info("Note: recommended maintenance dates are calculated based on predicted RUL. Machines with RED category should be scheduled immediately.")
    
    # Downloadable PDF report
    if base_df is not None and model_metrics is not None:
        pdf_buffer = build_pdf_report(base_df, model_metrics)
        st.markdown("---")
        st.subheader("Export")
        st.download_button(
            label="Download dashboard report (PDF)",
            data=pdf_buffer,
            file_name="delta_industries_predictive_maintenance_report.pdf",
            mime="application/pdf",
        )
    
    # Footer
    st.markdown("---")
    st.markdown("Delta Industries Ltd. | Predictive Maintenance System | Generated for project evaluation")

if __name__ == "__main__":
    main()
